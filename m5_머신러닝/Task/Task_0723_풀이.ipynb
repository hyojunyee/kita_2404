{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNwRVEGuUNugxqOo3XGW4CW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyojunyee/kita_2404/blob/main/m5_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D/Task/Task_0723_%ED%92%80%EC%9D%B4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task1_0723. 'Breast Cancer Wisconsin (Diagnostic) Data Set'을 사용하여 이진 분류 문제를 해결하고, 평가 지표(정확도, 정밀도, 재현율, F1 스코어, ROC AUC)를 계산하세요."
      ],
      "metadata": {
        "id": "jyOaFOg5QkLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "# 데이터 로드\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# 특성과 라벨\n",
        "X = data.data\n",
        "y = (data.target == 0).astype(int)\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 평가지표(정확도, 정밀도, 재현율, F1 스코어, ROC AUC)를 계산 함수 작성\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    confusion = confusion_matrix(y_test, y_pred)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "    print(f'오차 행렬:\\n{confusion}')\n",
        "    print(f'정확도: {accuracy:.4f}\\n 정밀도: {precision:.4f}\\n 재현율: {recall:.4f}\\n F1: {f1:.4f}\\n roc_auc {roc_auc:.4f}\\n')\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression' : LogisticRegression(max_iter=500, solver='lbfgs', random_state=42),\n",
        "    'Random Forest Classifier' : RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'Decision Tree Classifier' : DecisionTreeClassifier(random_state=42),\n",
        "    'Support Vector Machine' : SVC(probability=True, random_state=42) # probability=True는 확률 값을 반환하게 하여 predict_proba 메서드를 사용할 수 있게 함\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f'[{model_name}]')\n",
        "    evaluate_model(model, X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9g28NVlOSeR7",
        "outputId": "ad0806f8-409d-4e82-f6f4-88e5833115dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Logistic Regression]\n",
            "오차 행렬:\n",
            "[[70  1]\n",
            " [ 2 41]]\n",
            "정확도: 0.9737\n",
            " 정밀도: 0.9762\n",
            " 재현율: 0.9535\n",
            " F1: 0.9647\n",
            " roc_auc 0.9974\n",
            "\n",
            "[Random Forest Classifier]\n",
            "오차 행렬:\n",
            "[[70  1]\n",
            " [ 3 40]]\n",
            "정확도: 0.9649\n",
            " 정밀도: 0.9756\n",
            " 재현율: 0.9302\n",
            " F1: 0.9524\n",
            " roc_auc 0.9953\n",
            "\n",
            "[Decision Tree Classifier]\n",
            "오차 행렬:\n",
            "[[68  3]\n",
            " [ 3 40]]\n",
            "정확도: 0.9474\n",
            " 정밀도: 0.9302\n",
            " 재현율: 0.9302\n",
            " F1: 0.9302\n",
            " roc_auc 0.9440\n",
            "\n",
            "[Support Vector Machine]\n",
            "오차 행렬:\n",
            "[[71  0]\n",
            " [ 2 41]]\n",
            "정확도: 0.9825\n",
            " 정밀도: 1.0000\n",
            " 재현율: 0.9535\n",
            " F1: 0.9762\n",
            " roc_auc 0.9974\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task2_0723.\n",
        "가상의 데이터셋을 생성하고, 이를 사용하여 다중 클래스 분류 모델을 훈련시킨 후 평가 지표를 계산하세요. 평가 지표는 정확도, 정밀도, 재현율, F1 스코어, ROC AUC입니다."
      ],
      "metadata": {
        "id": "Jg5NG4KwQmi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- n_samples=1500: 데이터셋에 포함될 샘플의 수를 1500개로 지정합니다.\n",
        "- n_features=20: 각 샘플이 가질 특성(feature)의 수를 20개로 지정합니다.\n",
        "- n_classes=5: 타겟 라벨의 클래스 수를 5개로 지정합니다.\n",
        "- n_informative=15: 20개의 특성 중 15개는 타겟 라벨과 관련된 유용한 정보를 포함하도록 지정합니다. 나머지 5개의 특성은 유용하지 않거나 무작위로 생성된 특성입니다.\n",
        "- random_state=42: 재현성을 위해 난수 생성 seed를 설정합니다."
      ],
      "metadata": {
        "id": "KoYG87gzQ40n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "average 매개변수에는 여러 가지 옵션이 있으며, 각 옵션은 다중 클래스 데이터에 대한 정밀도를 계산하는 다른 방법을 제공\n",
        "\n",
        "[ average 매개변수 옵션 ]\n",
        "- average='macro':\n",
        "각 클래스의 정밀도를 개별적으로 계산한 후, 단순 평균을 구합니다.\n",
        "모든 클래스가 동일하게 가중치를 부여받습니다.\n",
        "클래스 간 불균형이 있을 때 유용합니다.\n",
        "- average='micro':\n",
        "전체 TP, FP, FN을 합쳐서 정밀도를 계산합니다.\n",
        "모든 샘플을 개별적으로 동일하게 취급한다.\n",
        "- average='weighted':\n",
        "각 클래스의 정밀도를 개별적으로 계산한 후, 클래스별 샘플 수로 가중 평균을 구합니다.\n",
        "클래스의 샘플 수에 따라 가중치를 부여합니다.\n",
        "- average='samples' (다중 레이블 분류에 사용됨):\n",
        "각 샘플에 대해 개별적으로 메트릭을 계산한 후 평균을 구합니다.\n",
        "- average=None:\n",
        "각 클래스별로 정밀도를 반환합니다. 다중 클래스 분류에서 각 클래스에 대한 정밀도를 별도로 얻을 수 있습니다."
      ],
      "metadata": {
        "id": "n4uP6zoKNSHz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# 데이터 생성 (5개의 클래스)\n",
        "X, y = make_classification(n_samples=1500, n_features=20, n_classes=5, n_informative=15, random_state=42)\n",
        "\n",
        "# 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 훈련\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 예측\n",
        "y_pred = model.predict(X_test)\n",
        "y_score = model.predict_proba(X_test)\n",
        "\n",
        "# 다중 클래스 라벨을 이진화\n",
        "y_test_binarized = label_binarize(y_test, classes=[0, 1, 2, 3, 4])\n",
        "\n",
        "# 평가 지표 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "roc_auc = roc_auc_score(y_test_binarized, y_score, multi_class='ovr')\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(f'오차 행렬:\\n{confusion}')\n",
        "print(f'정확도: {accuracy:.4f}')\n",
        "print(f'정밀도: {precision:.4f}')\n",
        "print(f'재현율: {recall:.4f}')\n",
        "print(f'F1 스코어: {f1:.4f}')\n",
        "print(f'ROC AUC: {roc_auc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVNfW10CnO9m",
        "outputId": "cfe98ac3-2f66-4d16-9d70-c8714c886b51"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬:\n",
            "[[52  6  2  7  1]\n",
            " [ 1 46  2  0  5]\n",
            " [ 0  6 49  2  2]\n",
            " [ 5  2  4 46  6]\n",
            " [ 5  4  2  1 44]]\n",
            "정확도: 0.7900\n",
            "정밀도: 0.7909\n",
            "재현율: 0.7926\n",
            "F1 스코어: 0.7898\n",
            "ROC AUC: 0.9481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from collections import Counter\n",
        "\n",
        "# 데이터셋 로드\n",
        "digits = load_digits()\n",
        "X, y = digits.data, digits.target\n",
        "\n",
        "# 훈련 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 모델 훈련\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 예측\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 평가 지표 계산\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "# 출력 레이블 이진화\n",
        "y_test_binarized = label_binarize(y_test, classes=np.arange(10))\n",
        "y_pred_binarized = label_binarize(y_pred, classes=np.arange(10))\n",
        "\n",
        "# 클래스가 충분히 있는지 확인\n",
        "if np.any(np.sum(y_test_binarized, axis=0) == 0):\n",
        "    print(\"테스트 데이터에 모든 클래스가 포함되어 있지 않습니다.\")\n",
        "else:\n",
        "    # ROC AUC 계산 (OvR 방식)\n",
        "    roc_auc_ovr = roc_auc_score(y_test_binarized, y_pred_binarized, average='weighted', multi_class='ovr')\n",
        "\n",
        "    # ROC AUC 계산 (OvO 방식)\n",
        "    roc_auc_ovo = roc_auc_score(y_test_binarized, y_pred_binarized, average='weighted', multi_class='ovo')\n",
        "\n",
        "    # 평가 지표 출력\n",
        "    print(f\"정확도: {accuracy:.2f}, 정밀도: {precision:.2f}, 재현율: {recall:.2f}, F1 Score: {f1:.2f}\")\n",
        "    print(f\"ROC AUC (OvR): {roc_auc_ovr:.2f}, ROC AUC (OvO): {roc_auc_ovo:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRFdR1aPoC3E",
        "outputId": "dc28299a-9f8b-4459-fd4d-c04497ac08ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정확도: 0.97, 정밀도: 0.97, 재현율: 0.97, F1 Score: 0.97\n",
            "ROC AUC (OvR): 0.98, ROC AUC (OvO): 0.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task3_0723. Task1_2022를 개선하시오"
      ],
      "metadata": {
        "id": "J0JB8yuMSLyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 1. 데이터 로드\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
        "columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "           'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
        "           'hours-per-week', 'native-country', 'income']\n",
        "data = pd.read_csv(url, header=None, names=columns, na_values='?', skipinitialspace=True)\n",
        "\n",
        "# 2. 결측치 처리\n",
        "# 수치형 변수의 결측치를 중앙값으로 대체\n",
        "numeric_features = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "imputer_numeric = SimpleImputer(strategy='median')\n",
        "data[numeric_features] = imputer_numeric.fit_transform(data[numeric_features])\n",
        "\n",
        "# 범주형 변수의 결측치를 최빈값으로 대체\n",
        "categorical_features = data.select_dtypes(include=[object]).columns.tolist()\n",
        "categorical_features.remove('income')\n",
        "imputer_categorical = SimpleImputer(strategy='most_frequent')\n",
        "data[categorical_features] = imputer_categorical.fit_transform(data[categorical_features])\n",
        "\n",
        "# 3. 이상치 제거 (여기서는 'capital-gain'과 'capital-loss'에서 극단적인 값들을 이상치로 가정)\n",
        "def replace_outliers_with_median(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    median = df[column].median()\n",
        "    df[column] = np.where((df[column] < lower_bound) | (df[column] > upper_bound), median, df[column])\n",
        "    return df\n",
        "\n",
        "for col in numeric_features:\n",
        "    data = replace_outliers_with_median(data, col)\n",
        "\n",
        "# 4. 파생변수 작성\n",
        "data['capital_diff'] = data['capital-gain'] - data['capital-loss']\n",
        "\n",
        "# 5. 범주형 변수 인코딩\n",
        "categorical_features = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "encoded_categorical_data = encoder.fit_transform(data[categorical_features])\n",
        "encoded_categorical_df = pd.DataFrame(encoded_categorical_data, columns=encoder.get_feature_names_out(categorical_features))\n",
        "\n",
        "# 원래 데이터프레임에서 범주형 열을 제거하고 인코딩된 데이터프레임을 병합\n",
        "data = data.drop(columns=categorical_features)\n",
        "data = pd.concat([data, encoded_categorical_df], axis=1)\n",
        "\n",
        "# 6. 변수 선택 및 데이터 분리\n",
        "# 'income' 변수를 0과 1로 변환\n",
        "data['income'] = data['income'].apply(lambda x: 1 if x.strip() == '>50K' else 0)\n",
        "X = data.drop('income', axis=1)\n",
        "y = data['income']\n",
        "\n",
        "# 7. 데이터 표준화\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 8. 학습용과 테스트용 데이터셋으로 나누기\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 9. Logistic Regression 모델 생성 및 학습\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 10. 예측 및 평가\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy: {accuracy:.2f}')\n",
        "print('Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "print('Classification Report:')\n",
        "print(class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMAV7P3_SMVs",
        "outputId": "aa901cac-5d0e-4b48-f38a-eccc7eb52dd2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.83\n",
            "Confusion Matrix:\n",
            "[[4563  382]\n",
            " [ 706  862]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.92      0.89      4945\n",
            "           1       0.69      0.55      0.61      1568\n",
            "\n",
            "    accuracy                           0.83      6513\n",
            "   macro avg       0.78      0.74      0.75      6513\n",
            "weighted avg       0.82      0.83      0.83      6513\n",
            "\n"
          ]
        }
      ]
    }
  ]
}