{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1_0619. 다음 사항을 수행하세요.\n",
    "- 첫 번째로 매칭되는 'p' 태그 찾기\n",
    "- 모든 'p' 태그 찾기\n",
    "- 클래스가 'content'인 첫 번째 'p' 태그 찾기\n",
    "- 클래스가 'content'인 모든 'p' 태그 찾기\n",
    "- 특정 'p' 태그의 모든 부모 태그 찾기\n",
    "- 특정 'p' 태그의 첫 번째 부모 태그 찾기\n",
    "- 특정 'p' 태그의 다음 형제 태그 찾기\n",
    "- 특정 'p' 태그의 이전 형제 태그 찾기\n",
    "- 특정 'p' 태그 다음에 위치한 모든 태그나 문자열 찾기\n",
    "- 특정 'p' 태그 이전에 위치한 모든 태그나 문자열 찾기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   Title\n",
      "  </h1>\n",
      "  <p class=\"content\">\n",
      "   First paragraph.\n",
      "  </p>\n",
      "  <p class=\"content\">\n",
      "   Second paragraph.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_content = '<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>'\n",
    "soup = BeautifulSoup(html_content,'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"content\">First paragraph.</p>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째로 매칭되는 'p' 태그 찾기\n",
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"content\">First paragraph.</p>,\n",
       " <p class=\"content\">Second paragraph.</p>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 'p' 태그 찾기\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"content\">First paragraph.</p>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 클래스가 'content'인 첫 번째 'p' 태그 찾기\n",
    "soup.find('p', class_='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스가 'content'인 모든 'p' 태그 찾기\n",
    "soup.find_all('p', class_='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 'p' 태그 선택\n",
    "p_tag = soup.find('p')\n",
    "\n",
    "# 첫 번째 부모 태그 찾기 (div 태그)\n",
    "parent_tag = p_tag.find_parent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>]\n"
     ]
    }
   ],
   "source": [
    "# 특정 'p' 태그의 모든 부모 태그 찾기\n",
    "p_tag = soup.find('p')\n",
    "print(p_tag.find_parents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>]\n",
      "[<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>]\n"
     ]
    }
   ],
   "source": [
    "p_tags = soup.select('p')\n",
    "\n",
    "for p_tag in p_tags:\n",
    "  parent_tag = p_tag.find_parents()\n",
    "  print(parent_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>\n"
     ]
    }
   ],
   "source": [
    "# 특정 'p' 태그의 첫 번째 부모 태그 찾기\n",
    "# p_tags = soup.select('p')\n",
    "# print(p_tag.find_parent())\n",
    "p_tag = soup.find('p')\n",
    "print(p_tag.find_parent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">Second paragraph.</p>\n"
     ]
    }
   ],
   "source": [
    "# 특정 'p' 태그의 다음 형제 태그 찾기\n",
    "# p_tag = soup.find('p')\n",
    "# print(p_tag.find_next_sibling())\n",
    "p_tag = soup.select_one('p')\n",
    "print(p_tag.find_next_sibling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Title</h1>\n"
     ]
    }
   ],
   "source": [
    "# 특정 'p' 태그의 이전 형제 태그 찾기\n",
    "# p_tag = soup.find('p')\n",
    "# print(p_tag.find_previous_sibling())\n",
    "p_tag = soup.select_one('p')\n",
    "print(p_tag.find_previous_sibling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 'p' 태그 다음에 위치한 모든 태그나 문자열 찾기\n",
    "p_tags = soup.select('.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 특정 'p' 태그 이전에 위치한 모든 태그나 문자열 찾기 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2_0619. ID를 이용해서 '네이버 뉴스' 추출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://news.naver.com/'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Referer': 'http://example.com',\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title id=\"browserTitleArea\">네이버 뉴스</title>\n",
      "네이버 뉴스\n",
      "네이버 뉴스\n"
     ]
    }
   ],
   "source": [
    "news_title = soup.find('title')\n",
    "print(news_title)\n",
    "print(news_title.get_text())\n",
    "print(news_title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3_0619. soup.find_all(class_='Nitem_link_menu') 대신에 select를 이용하여 동일한 결과를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:언론사별\n",
      "1:정치\n",
      "2:경제\n",
      "3:사회\n",
      "4:생활/문화\n",
      "5:IT/과학\n",
      "6:세계\n",
      "7:랭킹\n",
      "8:신문보기\n",
      "9:오피니언\n",
      "10:TV\n",
      "11:팩트체크\n",
      "12:알고리즘 안내\n",
      "13:정정보도 모음\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "cats = soup.select('.Nitem_link_menu')\n",
    "for idx, cat in enumerate(cats):\n",
    "    print(f\"{idx}:{cat.get_text().strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task4_0619. select_one을 이용해서 'https://news.naver.com'에서 \"뉴스\"를 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스\n"
     ]
    }
   ],
   "source": [
    "# 동적 콘텐츠 로딩 : selenium 사용\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('--start-maximized')\n",
    "options.add_experimental_option('detach', True)\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# 네이버 뉴스 페이지 열기\n",
    "url = 'https://news.naver.com/'\n",
    "driver.get(url)\n",
    "\n",
    "# 페이지 로딩 대기\n",
    "time.sleep(2)\n",
    "\n",
    "# 뉴스 링크 찾기\n",
    "try:\n",
    "    newsstand_link = driver.find_element(By.CSS_SELECTOR, 'body > section > header > div.Ngnb > div > div > div.Ngnb_left > div > h1 > a')\n",
    "    print(newsstand_link.text)\n",
    "except:\n",
    "    print(\"뉴스를 찾을 수 없습니다\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task5_0619.'https://news.naver.com'에서 아래 예시와 같이 뉴스 기사 제목을 모두 출력하세요. \n",
    "\n",
    "예시: 1: [속보] '훈련병 사망' 얼차려 지시 중대장·부중대장 피의자 신분 첫 소환조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : \"러브버그 너무 징그러워서 소름\"…달라붙어도 죽이지 말라고?\n",
      "2 : “초대박 터졌다”...편의점 주류판 흔드는 CU\n",
      "3 : Putin, Kim likely to discuss military ties as rare summit talks begin\n",
      "4 : \"중화상 입은 팀장 결국 숨져\".. 다른 작업자도 '중태'\n",
      "5 : 손흥민 손 꼭 잡고 “왜 이리 말랐어”... 치매 할머니 팬의 감동 만남\n",
      "6 : 국민의힘, 민주당에 \"법사위·운영위 1년씩 번갈아 맡자\" 제안\n",
      "7 : \"잘 나가던 수지 어쩌나\" BJ 천국 아프리카TV 때문에 '경악'\n",
      "8 : '성심당 월세 4억' 악덕 건물주 비난에…코레일이 꺼낸 카드\n",
      "9 : 홍준표 아이디어로 대구에 ‘프러포즈 성지’ 만든다…비용만 110억원\n",
      "10 : ‘대유행’ 시간문제라던데… ‘치명률 52%’ 조류인플루엔자, 인류 위협할까\n",
      "11 : 투르크 국견 알라바이 입국, 대통령 관저로…\"향후 외부서 사육\"\n",
      "12 : 톱스타 한명 없는데 시청률 터졌다…'우영우' 이은 대박 드라마\n",
      "13 : 목동 아파트 화재 대응 1단계 발령…소방관 14명 부상\n",
      "14 : 5번 유찰된 ‘대전역 성심당’ 자리… 코레일의 다음 카드는?\n",
      "15 : 사막에 도대체 이게 뭐야?...정체불명 금속기둥 '모노리스'\n",
      "16 : 최태원-노소영 이혼소송, 끝날 때까지 끝난 게 아니다\n",
      "17 : 의료계도 선 그은 의협 회장…\"무기한 휴진, 황당\"\n",
      "18 : [의대증원 파장] 개원의 무관심에 전공의 내분까지…무기한 휴진도 '글쎄'\n",
      "19 : [현장영상]‘조국 아들 인턴’ 발언 최강욱, 2심 벌금형 선고에 “어이가 없어서…”\n",
      "20 : 韓 푸드테크 창발가 한자리…이기원 회장 \"반도체 버금갈 세계 넘버원 될 것\"\n",
      "21 : Will striking doctors go the distance?\n",
      "22 : '가상자산 차익거래' 목적 외화 밀반출 증가…단속 강화된다\n",
      "23 : 윤석열 정부 고위 검사 '3분의 2'가 특수활동비 오남용 의혹\n",
      "24 : \"타격 우려\" \"의협 대표성 하락\"…의사들 '휴진 참여율' 낮은 이유는\n",
      "25 : 석유공사 사장 “글로벌 업체 5곳, 동해 가스전에 투자 관심”\n",
      "26 : 경제학자 \"물가 내렸다\" vs 서민 \"올랐다\" 그 이유는? [마켓톡톡]\n",
      "27 : KBS에 감사실장 2명이 출근하게 된 웃지 못할 사연\n",
      "28 : 김호중, 술 마셨지만 음주운전 '무혐의'… 음주량 특정 못해\n",
      "29 : \"용변 보는 아이, 지켜보는 보호자\" 주변 화장실 놔두고 왜.. 사진 한 장에 공분 확산\n",
      "30 : 박세리 父 “아버지니까 나설 수 있는 거 아닌가 생각”\n",
      "31 : 또 불출석 택한 이상민·윤희근... 행안위 '증인' 채택\n",
      "32 : 카이스트 교수 지드래곤, '성심당 빵 샀나?' 알고 보니…\n",
      "33 : ‘채상병 특검법’ 청문회 D-2, 박정훈 대령의 심경은? [김은지의 뉴스IN]\n",
      "34 : 울분 토한 이화영 옥중서신 “檢, 이재명 기소 성공…전 감옥서 이대로 썩으라고”\n",
      "35 : 김정은 극도의 스트레스?…얼굴서 포착된 '이상 징후' 부쩍 커졌다\n",
      "36 : 살 파고 들어간 구더기 ‘한가득’…처참한 상태로 발견된 레트리버\n",
      "37 : “고혈압, 심장혈관병 다 있는 사람 너무 많아”...꼭 바꿔야 할 ‘이 식습관’은?\n",
      "38 : 北 '최고의 국빈' 강조했지만...예상외로 조촐한 환영\n",
      "39 : [단독]\"가게 문 자주 닫고 배달 안해\" 백종원 압박 점주들, 매출 낮은 이유\n",
      "40 : 투르크메니스탄 국견 ‘알라바이’ 대통령 관저서 서울 생활 시작\n",
      "41 : \"1억 주면 조용히 있겠다\"…'연돈볼카츠' 공방 속 녹취록 공개 파장\n",
      "42 : 의협 \"무기한 휴진\"… 의료계 내부 \"처음 듣는 소리, 황당\"\n",
      "43 : 의협 '무기한 휴진'에 불협화음…경기의사회장 \"처음 들어\"\n",
      "44 : 홍준표, 이재명 겨냥 “여의도 동탁 탄생.. 처단해줄 여포 기다리는 사람 늘어가”\n",
      "45 : [속보] 尹대통령, '인구 국가비상사태' 선언…\"범국가적 총력 대응, 아빠 출산휴가 20일로 확대\"\n",
      "46 : ‘인구비상사태’ 선언에…‘그린벨트’ 풀고, ‘특공’ 재당첨까지 허용\n",
      "47 : 탐욕스러운 돌봄\n",
      "48 : “믿기지 않는다”…유명 女배우, 54세에 자연임신 성공\n",
      "49 : 재난의 추억, 지하가 위험하다[칼럼]\n",
      "50 : 서울 35.6도, 경주 37.7도, 경산 39도…역대 6월 '가장 더운 날'\n",
      "51 : 하루만에 6천, 5일만에 1억...밀양 성폭력 피해자 위해 3천명이 나섰다\n",
      "52 : \"압도적인 차\"…독일·영국서 호평 일색\n",
      "53 : ‘김정숙 외유논란’ 수사착수 시점에…文은 감자 사진\n",
      "54 : [단독]‘몰카 안경’ 쓰고 유치장-판사 몰래 찍은 30대 여성 구속기소\n",
      "55 : “조국 아들 인턴” 허위 발언 최강욱, 2심도 벌금 80만원\n",
      "56 : [속보] 尹 \"'인구 국가비상사태' 선언… 양육·주거 등 지원 확대\"\n",
      "57 : 박세리 父, 딸 몰래 도장 만든 이유… “내가 아버지니까”\n",
      "58 : 윤 대통령 집권 3년차 인적쇄신 또 용두사미?\n",
      "59 : '7년 만났는데' 알고 보니 유부남..엽산이라 속여 낙태약 먹이기도\n",
      "60 : '사망 훈련병' 어머니의 눈물 \"수료생 251명 중 우리 아들만 없어\"\n",
      "61 : 검찰, 김건희 여사 측근 행정관 소환‥대통령실 인사 첫 조사\n",
      "62 : “귀엽지만 음식에 털 날려서…” 반려동물 식당 출입에 곳곳 갈등\n",
      "63 : 여전히 위험한 부산 스쿨존…주차장 방치되고 펜스는 허술\n",
      "64 : 공단 근무 밀양 가해자, 결국 사직서 냈다\n",
      "65 : 실질 지원 기대감 “해봐야”…익명 출산 딜레마 “해봤자”\n",
      "66 : \"왜 남의 나라 더럽혀\"... 제주 길거리서 아이 대변보게 한 중국인 관광객\n",
      "67 : '조국 아들 인턴 허위 발언' 최강욱 2심도 유죄…\"대법원 간다\"\n",
      "68 : 뉴스 이용 설문 응답자 39% \"뉴스 피한다\"... 역대 최고\n",
      "69 : 목동 아파트에 불, 대응1단계…소방청장 현장 지휘, 대원 14명 부상\n",
      "70 : 육아휴직 급여 '최대 250만원'으로…\"아빠 참여 늘려야\"[저출생 대책]\n",
      "71 : 목사님 강의에 찬송가도…이 회사에 무슨 일이?\n",
      "72 : 농가소득 안전망 최대 화두 속 ‘농민수당 법제화’ 첫발\n",
      "73 : [단독] 밀양시 공단 근무 '여중생 집단 성폭행 사건' 가해자 사직서 제출\n",
      "74 : 방문 요양보호사들 ‘임금 올려라’ 국가에 소송 제기\n",
      "75 : [속보] 목동 주상복합아파트 지하주차장 불…'대응 1단계'\n",
      "76 : \"당근 빼달라\" 요청 들어줬는데..음식 받고 \"당근 상했으니 환불해줘\" 황당\n",
      "77 : SK하이닉스·삼성전자, HBM부터 낸드까지 '하이브리드 본딩' 도입 잰걸음\n",
      "78 : 해외로 떠나는 한국 부자들… 역대 최대치\n",
      "79 : [제4이통 백지화]④ 주파수 할당 취소 후폭풍, 스테이지파이브 어떡하나\n",
      "80 : [속보] 국힘, 강민구 \"이재명은 아버지\" 발언에 \"조선노동당이냐\"\n",
      "81 : [지도 위를 걷다 마적산] 말끔하면서도 거친 춘천의 미니 종주코스\n",
      "82 : 이재명 “단통법 신속 폐지하겠다… 통신비 부담 낮춰야”\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL 설정\n",
    "url = \"https://news.naver.com/\"\n",
    "\n",
    "# HTML 파싱\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 뉴스 기사 제목 추출\n",
    "# news_titles = soup.find_all(class_='cjs_t')  # 뉴스 기사 제목 요소 선택\n",
    "news_titles = soup.select('.cjs_t')  # 뉴스 기사 제목 요소 선택\n",
    "# print(news_titles)\n",
    "# 제목 출력\n",
    "for i,title in enumerate(news_titles):\n",
    "    print(f\"{i+1} : {title.text.strip()}\")\n",
    "# count = 1\n",
    "# for title in news_titles:\n",
    "#     print(f\"{count}: {title.text.strip()}\")\n",
    "#     count += 1\n",
    "\n",
    "# 리스트로 뽑아보기\n",
    "# news_titles_text = [title.text.strip() for title in news_titles]\n",
    "# print(news_titles_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
