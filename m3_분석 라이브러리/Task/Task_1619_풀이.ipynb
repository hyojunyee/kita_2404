{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1_0619. 다음 사항을 수행하세요.\n",
    "- 첫 번째로 매칭되는 'p' 태그 찾기\n",
    "- 모든 'p' 태그 찾기\n",
    "- 클래스가 'content'인 첫 번째 'p' 태그 찾기\n",
    "- 클래스가 'content'인 모든 'p' 태그 찾기\n",
    "- 특정 'p' 태그의 모든 부모 태그 찾기\n",
    "- 특정 'p' 태그의 첫 번째 부모 태그 찾기\n",
    "- 특정 'p' 태그의 다음 형제 태그 찾기\n",
    "- 특정 'p' 태그의 이전 형제 태그 찾기\n",
    "- 특정 'p' 태그 다음에 위치한 모든 태그나 문자열 찾기\n",
    "- 특정 'p' 태그 이전에 위치한 모든 태그나 문자열 찾기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   Title\n",
      "  </h1>\n",
      "  <p class=\"content\">\n",
      "   First paragraph.\n",
      "  </p>\n",
      "  <p class=\"content\">\n",
      "   Second paragraph.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html_content = '<html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>'\n",
    "soup = BeautifulSoup(html_content,'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">First paragraph.</p>\n",
      "First paragraph.\n"
     ]
    }
   ],
   "source": [
    "# 첫 번째로 매칭되는 'p' 태그 찾기\n",
    "first_p = soup.find('p')\n",
    "print(first_p)\n",
    "print(first_p.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">First paragraph.</p>\n",
      "<p class=\"content\">Second paragraph.</p>\n",
      "First paragraph.\n",
      "Second paragraph.\n"
     ]
    }
   ],
   "source": [
    "# 모든 'p' 태그 텍스트 찾기\n",
    "all_p = soup.find_all('p')\n",
    "for p in all_p:\n",
    "    print(p)\n",
    "    \n",
    "for p in all_p:\n",
    "    print(p.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"content\">First paragraph.</p>, <p class=\"content\">Second paragraph.</p>]\n"
     ]
    }
   ],
   "source": [
    "# 모든 'p' 태그 리스트로 찾기\n",
    "all_p = soup.find_all('p')\n",
    "print(all_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">First paragraph.</p>\n"
     ]
    }
   ],
   "source": [
    "# 클래스가 'content'인 첫 번째 'p' 태그 찾기\n",
    "f_c_p = soup.find('p', class_='content')\n",
    "# f_c_p = soup.select_one('p.content')\n",
    "print(f_c_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">First paragraph.</p>\n",
      "<p class=\"content\">Second paragraph.</p>\n",
      "[<p class=\"content\">First paragraph.</p>, <p class=\"content\">Second paragraph.</p>]\n"
     ]
    }
   ],
   "source": [
    "# 클래스가 'content'인 모든 'p' 태그 찾기\n",
    "a_c_p = soup.find_all('p', class_='content')\n",
    "# a_c_p = soup.select('p.content')\n",
    "for acp in a_c_p:\n",
    "    print(acp)\n",
    "# !!! 그냥 프린트하면 리스트로나옴\n",
    "print(a_c_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">First paragraph.</p> \n",
      "\n",
      "<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>\n"
     ]
    }
   ],
   "source": [
    "# 특정 'p' 테그의 부모 태그 찾기\n",
    "specific_p = soup.find('p', class_='content')\n",
    "print(specific_p,'\\n')\n",
    "# [document] -> <html> -> <p> : 최상위 요소 document에서 시작하여 p 태그 까지의 모든 부모 요소를 출력\n",
    "parents = specific_p.find_parents()\n",
    "print(parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body\n"
     ]
    }
   ],
   "source": [
    "### 첫 번째 부모 태그 찾기\n",
    "parent = specific_p.find_parent()\n",
    "print(parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>]\n"
     ]
    }
   ],
   "source": [
    "# 특정 'p' 태그의 모든 부모 태그 찾기\n",
    "p_tag = soup.find('p')\n",
    "print(p_tag.find_parents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>]\n",
      "[<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>, <html><body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body></html>]\n"
     ]
    }
   ],
   "source": [
    "p_tags = soup.select('p')\n",
    "\n",
    "for p_tag in p_tags:\n",
    "  parent_tag = p_tag.find_parents()\n",
    "  print(parent_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<body><h1>Title</h1><p class=\"content\">First paragraph.</p><p class=\"content\">Second paragraph.</p></body>\n"
     ]
    }
   ],
   "source": [
    "# 특정 'p' 태그의 첫 번째 부모 태그 찾기\n",
    "# p_tags = soup.select('p')\n",
    "# print(p_tag.find_parent())\n",
    "p_tag = soup.find('p')\n",
    "print(p_tag.find_parent())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">Second paragraph.</p>\n"
     ]
    }
   ],
   "source": [
    "# 특정 'p' 태그의 다음 형제 태그 찾기\n",
    "# p_tag = soup.find('p')\n",
    "# print(p_tag.find_next_sibling())\n",
    "p_tag = soup.select_one('p')\n",
    "print(p_tag.find_next_sibling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second paragraph.\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "next_sibling = specific_p.find_next_sibling()\n",
    "print(next_sibling.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Title</h1>\n"
     ]
    }
   ],
   "source": [
    "# 특정 'p' 태그의 이전 형제 태그 찾기\n",
    "# p_tag = soup.find('p')\n",
    "# print(p_tag.find_previous_sibling())\n",
    "p_tag = soup.select_one('p')\n",
    "print(p_tag.find_previous_sibling())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "previous_sibling = specific_p.find_previous_sibling()\n",
    "print(previous_sibling.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"content\">Second paragraph.</p>\n"
     ]
    }
   ],
   "source": [
    "# 특정 'p' 태그 다음에 위치한 모든 태그나 문자열 찾기\n",
    "next_elements = specific_p.find_next()\n",
    "print(next_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>Title</h1>\n"
     ]
    }
   ],
   "source": [
    "# 특정 'p' 태그 이전에 위치한 모든 태그나 문자열 찾기 \n",
    "previous_elements = specific_p.find_previous()\n",
    "print(previous_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task2_0619. ID를 이용해서 '네이버 뉴스' 추출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url = 'https://news.naver.com/'\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Referer': 'http://example.com',\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "response\n",
    "\n",
    "soup = BeautifulSoup(response.text,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title id=\"browserTitleArea\">네이버 뉴스</title>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'네이버 뉴스'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ID 사용해서\n",
    "news_title = soup.find('title',id='browserTitleArea')\n",
    "print(news_title)\n",
    "news_title.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# css 선택자 사용해서\n",
    "news_title = soup.select_one('browserTitleArea')\n",
    "print(news_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title id=\"browserTitleArea\">네이버 뉴스</title>\n",
      "네이버 뉴스\n",
      "네이버 뉴스\n"
     ]
    }
   ],
   "source": [
    "news_title = soup.find('title')\n",
    "print(news_title)\n",
    "print(news_title.get_text())\n",
    "print(news_title.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3_0619. soup.find_all(class_='Nitem_link_menu') 대신에 select를 이용하여 동일한 결과를 출력하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:언론사별\n",
      "1:정치\n",
      "2:경제\n",
      "3:사회\n",
      "4:생활/문화\n",
      "5:IT/과학\n",
      "6:세계\n",
      "7:랭킹\n",
      "8:신문보기\n",
      "9:오피니언\n",
      "10:TV\n",
      "11:팩트체크\n",
      "12:알고리즘 안내\n",
      "13:정정보도 모음\n"
     ]
    }
   ],
   "source": [
    "cats = soup.find_all(class_='Nitem_link_menu')\n",
    "for idx, cat in enumerate(cats):\n",
    "    print(f\"{idx}:{cat.get_text().strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:언론사별\n",
      "1:정치\n",
      "2:경제\n",
      "3:사회\n",
      "4:생활/문화\n",
      "5:IT/과학\n",
      "6:세계\n",
      "7:랭킹\n",
      "8:신문보기\n",
      "9:오피니언\n",
      "10:TV\n",
      "11:팩트체크\n",
      "12:알고리즘 안내\n",
      "13:정정보도 모음\n"
     ]
    }
   ],
   "source": [
    "cats = soup.select('.Nitem_link_menu')\n",
    "for idx, cat in enumerate(cats):\n",
    "    print(f\"{idx}:{cat.get_text().strip()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task4_0619. select_one을 이용해서 'https://news.naver.com'에서 \"뉴스\"를 출력하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "item_elemet = soup.select_one('span.Nicon_service')\n",
    "print(item_elemet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task5_0619.'https://news.naver.com'에서 아래 예시와 같이 뉴스 기사 제목을 모두 출력하세요. \n",
    "\n",
    "예시: 1: [속보] '훈련병 사망' 얼차려 지시 중대장·부중대장 피의자 신분 첫 소환조사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : “자식 돈에 어디 숟가락”…박세리 논란에 소환된 손웅정\n",
      "2 : 프랑스 13세 소년들, 12세 유대인 소녀 집단 성폭행 파문\n",
      "3 : \"李 민주당의 아버지\" 찬사에…진중권 \"아바이 수령, 이재명 주석 만세!\"\n",
      "4 : \"자식 돈은 자식 돈, 어디 숟가락을 얹나\"…박세리 논란에 손흥민 父 손웅정 발언 재조명\n",
      "5 : 끝모를 쌀값 하락…“재고 15만t 신속 격리를”\n",
      "6 : 1주기 앞두고 오송참사 현장 찾은 유족들 '짙은 안타까움'...재개통 우려도\n",
      "7 : 방문 요양보호사들 ‘임금 올려라’ 국가에 소송 제기\n",
      "8 : 2025년 직장인 쉬는 날 119일…3일 이상 연휴 6번\n",
      "9 : 길거리서 용변 본 아이, 엄마는 나 몰라라.. \"몰상식 행위  처벌해야\"\n",
      "10 : \"한쪽 침략당하면 상호지원\"…랍스터 먹고, 한밤 배웅까지\n",
      "11 : 실질 지원 기대감 “해봐야”…익명 출산 딜레마 “해봤자”\n",
      "12 : 정신질환으로 우발적 살인? '심신미약'이면 여성 살해해도 되나\n",
      "13 : 푸틴, 24년만의 방북…21시간 머물고 김정은 배웅 속 평양 떠나\n",
      "14 : [인사이드 스토리]반전 거듭하는 애플…아이폰 슈퍼사이클 맞을까\n",
      "15 : 현빈이 입은 '이 옷' 해외서도 난리…주가 58% 뛰었는데 \"더 뛴다\"\n",
      "16 : 오물 풍선 소동, 끝난 게 아니다\n",
      "17 : \"몸이 갑자기 거인처럼 커진다\" 감각이 왜곡된다는 女, 무슨 증후군?\n",
      "18 : 하늘에서 내려오는 ‘공짜’ 다이어트 보조제… 지금 실컷 누리자\n",
      "19 : 목동 아파트 화재 12시간 만에 진압…긴박했던 순간들\n",
      "20 : 백종원·곽튜브 제쳤다… 한국인이 좋아하는 유튜버 1위는?\n",
      "21 : Summit of two loners: Kim breaks seclusion with Putin by his side\n",
      "22 : [이사람] 영업이익 18조원 달성한 정의선 회장…국내 그룹 총수 중 '최고'\n",
      "23 : 이재명·한동훈 ‘단두대 매치’ 성사되나\n",
      "24 : 납품 전선 이상 無… 韓방산, 2분기 호실적 기대\n",
      "25 : '채 해병 사건 회수' 시작점에 윤석열... 새 통화 기록 나왔다\n",
      "26 : 민주당내 '이재명 아버지' 발언에 진중권 \"연호도 붙여줘라\"\n",
      "27 : [단독] 영화숙·재생원 악몽, 국제사회에 첫 증언\n",
      "28 : 은행 슈퍼앱, 디지털 헬스케어 품는다\n",
      "29 : 바지 벗고 길에 쪼그려 앉은 아이…제주 발칵 뒤집은 영상 [잇슈 키워드]\n",
      "30 : '김건희 논문 검증' 학생들 몰표‥'숙대'의 선택은\n",
      "31 : 내년 추석은 7일 쉰다…주5일 직장인 휴일 '119일'\n",
      "32 : “귀엽지만 음식에 털 날려서…” 반려동물 식당 출입에 곳곳 갈등\n",
      "33 : “비둘기, 멧돼지, 다람쥐 여러분…피임하세요” 과학자들 피임약 뿌려 개체수 조절 시험중\n",
      "34 : [인터뷰] “한국 넘버원 역직구 플랫폼 꿈꾸죠”…딜리버드코리아 직원들의 자신감\n",
      "35 : “시청률 0%, 터질게 터졌다” 넷플릭스발 초유의 사태 ‘발칵’\n",
      "36 : \"이게 무슨 추태냐\"...'대구 공무원 치킨집 갑질' 탄식에 홍준표 한마디\n",
      "37 : 尹, '채상병 기록 회수 당일' 개인폰으로 전방위 전화…이시원도 집중 연락\n",
      "38 : [단독]‘몰카 안경’ 쓰고 유치장-판사 몰래 찍은 30대 여성 구속기소\n",
      "39 : 한국인이 가장 좋아하는 유튜버 1위는?\n",
      "40 : 푸틴, 또 김정은에게 ‘러시아판 롤스로이스’ 아우루스 선물\n",
      "41 : 영국 명소 스톤헨지에 환경단체 주황 물감 스프레이 분사\n",
      "42 : 어제 ‘인구국가비상사태’ 보셨나요…‘진짜 비상사태’ 3가지 빠졌던데\n",
      "43 : 에코+페미, 우리 지금 만나\n",
      "44 : ‘형만 믿어’…한반도 유사시 러시아 개입 길 열렸다 [뉴스+]\n",
      "45 : 내년 추석 연휴는 1주일…개천절부터 한글날까지 쉰다\n",
      "46 : 종로 포차거리에서 흉기난동, 휴무 경찰이 제압\n",
      "47 : 카카오, '개인정보위 대상' 행정소송 준비…주요 로펌서 제안서 받아\n",
      "48 : 내년 '빨간 날'은 언제?…\"추석 대박\" 2025년 월력요항 발표\n",
      "49 : 서울 35도 ‘찜통더위’…제주 거센 장맛비\n",
      "50 : 대통령실 '길목' 첫 조사…관심 모드는 김건희 여사 조사\n",
      "51 : 김호중 음주운전 혐의 제외에…\"우리도 도망가자\" 공분\n",
      "52 : 북러, 포괄적 동반자 협정 체결 \"침략 당하면 상호지원\"\n",
      "53 : \"20년 넘게 알고 지낸 기자 질문에…\" 박세리 심경 고백\n",
      "54 : 정용진 신세계 '신상필벌' 인사에 직원들 ‘긴장’\n",
      "55 : 푸틴의 '탈(脫)달러'…\"베트남과 자국통화 무역 60%로 증가\"\n",
      "56 : ‘홍의 시대’ 열린다…막 오른 GS家 4세들의 승계 경쟁\n",
      "57 : “목에 여자 문신”…아동성범죄 저지른 한국 남성 공개한 나라\n",
      "58 : 징역 9년 6개월 이화영 판결문 속 이재명\n",
      "59 : 올해 장마 시작...제주 밤새 장맛비 내려\n",
      "60 : \"자식 돈에 어디 숟가락 얹나\"…박세리 논란에 손흥민父 재조명\n",
      "61 : 제주 길거리서 당당하게 대변보는 외국인 아이… 서경덕 \"반드시 처벌해 본보기 보여야\"\n",
      "62 : 비대면 대출 해준다더니…돌아온 건 계좌 정지\n",
      "63 : BBQ, '4000원 할인 쿠폰' 프로모션...민심 잡기 나선다\n",
      "64 : 에어컨 전기료 줄이는 방법은?\n",
      "65 : 박세리 부친 입 열었다 \"아빠니까 나설 수 있다는 생각\"\n",
      "66 : \"자식 돈은 자식 돈, 어디 숟가락을 얹나\"…박세리 논란에 손웅정 발언 재조명\n",
      "67 : 권도형 구금 몬테네그로 총리, 알고 보니 ‘테라 초기 투자자’\n",
      "68 : 제로라니까 제로인 줄 알았어? '제로슈거'의 거짓말 [추적+]\n",
      "69 : \"외로울 틈이 없어요\" 입주민들과 여행 가고 동아리 활동까지…'위스테이별내' 풍경[르포]\n",
      "70 : [도초도 수국축제] 지금 만나러 갑니다 1004만 송이 수국\n",
      "71 : 프랑스서 12세 유대인 소녀 집단 성폭행 발생…대중 '분노'\n",
      "72 : \"TV수신료 고지서 7월10일 도착한다\"\n",
      "73 : ‘미투’ 서지현 검사 근황 보니…“정치권, ‘이대남’ 표 위해 ‘女 지우기’ 급급”\n",
      "74 : \"옵션 추가하면 10억\"…전기차 첫 출시 앞둔 '이 브랜드' 판매 전략은\n",
      "75 : \"역대 가장 더운 6월\"..정읍 37.5도까지 치솟아\n",
      "76 : \"음주운전하면 무조건 튀어라\"…'음주 혐의' 빠진 김호중에 뿔난 여론\n",
      "77 : \"저출산 국가비상사태 선언\"…무더기 상한가 속출\n",
      "78 : AI가 광고를 만든다? \"중요한 건 인간의 판단력\"\n",
      "79 : “한달에 3천만원 저축, 연봉 5~6억”…악착같이 모은다는 무명개그맨의 정체\n",
      "80 : 尹 대통령 \"인구 국가비상사태\"…저출생 대책 드라이브 시동\n",
      "81 : 푸틴, 21시간 방북 종료…김정은, 비행기 뜰 때까지 손 흔들어\n",
      "82 : Putin, Kim sign strategic partnership as North backs Russia's war in Ukraine\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL 설정\n",
    "url = \"https://news.naver.com/\"\n",
    "\n",
    "# HTML 파싱\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# 뉴스 기사 제목 추출\n",
    "# news_titles = soup.find_all(class_='cjs_t')  # 뉴스 기사 제목 요소 선택\n",
    "news_titles = soup.select('.cjs_t')  # 뉴스 기사 제목 요소 선택\n",
    "# print(news_titles)\n",
    "# 제목 출력\n",
    "for i,title in enumerate(news_titles):\n",
    "    print(f\"{i+1} : {title.text.strip()}\")\n",
    "\n",
    "### count 사용\n",
    "# count = 1\n",
    "# for title in news_titles:\n",
    "#     print(f\"{count}: {title.text.strip()}\")\n",
    "#     count += 1\n",
    "\n",
    "# 리스트로 뽑아보기\n",
    "# news_titles_text = [title.text.strip() for title in news_titles]\n",
    "# print(news_titles_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
